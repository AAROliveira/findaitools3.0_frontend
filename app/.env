# Configurações do RAG Chatbot - FindAI Tools
# Copie este arquivo para .env e ajuste as configurações

# =============================================================================
# CONFIGURAÇÕES DO OLLAMA (RECOMENDADO)
# =============================================================================

# Usar Ollama para embeddings e LLM local
USE_OLLAMA=true

# URL base do Ollama
OLLAMA_BASE_URL=http://127.0.0.1:11434

# Modelos Ollama recomendados
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_CHAT_MODEL=deepseek-r1:1.5b

# Modelos alternativos (descomente para usar)
# OLLAMA_EMBEDDING_MODEL=mxbai-embed-large  # Melhor qualidade, mais pesado
# OLLAMA_EMBEDDING_MODEL=all-minilm         # Mais leve, mais rápido
# OLLAMA_CHAT_MODEL=mistral                 # Boa qualidade geral
# OLLAMA_CHAT_MODEL=llama3:8b               # Alta qualidade

# =============================================================================
# CONFIGURAÇÕES DO LLM (FALLBACK)
# =============================================================================

# Usar LLM local (true) ou OpenAI (false) - apenas se Ollama não estiver disponível
USE_LOCAL_LLM=true

# Chave da OpenAI (necessária se USE_LOCAL_LLM=false e USE_OLLAMA=false)
# OPENAI_API_KEY=sua_chave_aqui

# Caminho para modelo local (necessário se USE_LOCAL_LLM=true e USE_OLLAMA=false)
# LOCAL_MODEL_PATH=./models/llama-2-7b-chat.gguf

# =============================================================================
# CONFIGURAÇÕES DO SERVIDOR
# =============================================================================

# Host e porta do servidor FastAPI
SERVER_HOST=127.0.0.1
SERVER_PORT=8000

# Nível de log (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# CONFIGURAÇÕES DO RAG
# =============================================================================

# Diretório dos embeddings
EMBEDDINGS_DIR=../embeddings

# Limiar de similaridade para filtrar resultados
SIMILARITY_CUTOFF=0.7

# Número máximo de fontes retornadas
MAX_SOURCES=5

# =============================================================================
# CONFIGURAÇÕES DE SEGURANÇA
# =============================================================================

# Origens permitidas para CORS (separadas por vírgula)
# Para desenvolvimento local: http://localhost:3000,http://127.0.0.1:3000
# Para produção: https://seudominio.com
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Máximo de caracteres por pergunta
MAX_QUESTION_LENGTH=1000

# =============================================================================
# CONFIGURAÇÕES DE PERFORMANCE
# =============================================================================

# Número de workers para uvicorn (produção)
WORKERS=1

# Timeout para requests (segundos)
REQUEST_TIMEOUT=30
